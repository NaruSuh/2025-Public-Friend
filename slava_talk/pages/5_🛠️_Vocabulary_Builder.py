from typing import List

import streamlit as st

from modules.ai_client import AIClientError, generate_vocab_from_context
from modules.crawler import crawl_and_extract
from modules.data_loader import export_to_yaml, load_vocab, save_vocab
from modules.vocab_manager import merge_vocab, parse_yaml
from modules.ui_components import apply_custom_css, render_hero_section

st.set_page_config(page_title="Vocabulary Builder - SlavaTalk", page_icon="ğŸ› ï¸", layout="wide")
apply_custom_css()

DEFAULT_URLS = """https://en.wikipedia.org/wiki/Ukraine
https://en.wikipedia.org/wiki/Economy_of_Ukraine
https://en.wikipedia.org/wiki/Politics_of_Ukraine"""

if "builder_results" not in st.session_state:
    st.session_state.builder_results = []
    st.session_state.builder_warnings = []

render_hero_section(
    "ğŸ› ï¸ ë‹¨ì–´ ì¶”ê°€ ë„êµ¬",
    "AIë¡œ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìë™ ì¶”ì¶œ | YAML íŒŒì¼ ì—…ë¡œë“œ | ë‹¨ì–´ì¥ ê´€ë¦¬"
)

with st.expander("ğŸ“¥ Step 1. ì›¹ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ", expanded=True):
    urls_input = st.text_area("ğŸ“Œ URL ëª©ë¡ (í•œ ì¤„ì— í•˜ë‚˜ì”©)", value=DEFAULT_URLS, height=140)
    topics = st.multiselect(
        "ğŸ·ï¸ ì£¼ì œ ì„ íƒ",
        options=["diplomacy", "defense", "trade", "supply chain", "due diligence", "esg"],
        default=["diplomacy", "defense", "trade", "supply chain"],
    )
    max_terms = st.slider("ğŸ“Š ì†ŒìŠ¤ë‹¹ ìµœëŒ€ ë‹¨ì–´ ìˆ˜", min_value=5, max_value=30, value=12, step=1)
    proficiency = st.selectbox("ğŸ¯ í•™ìŠµì ë ˆë²¨", options=["novice", "intermediate", "advanced"], index=1)
    manual_text = st.text_area("âœï¸ ë˜ëŠ” í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ (ìš°í¬ë¼ì´ë‚˜ì–´/ì˜ì–´)", height=200, placeholder="ë‰´ìŠ¤ ê¸°ì‚¬, ë¬¸ì„œ, ê³„ì•½ì„œ ë“±ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...")

    if st.button("ğŸš€ AIë¡œ ë‹¨ì–´ ì¶”ì¶œ ì‹œì‘", type="primary"):
        urls = [line.strip() for line in urls_input.splitlines() if line.strip()]
        results: List[dict] = []
        warnings: List[str] = []

        with st.spinner("Processing sources with ChatGPTâ€¦"):
            if urls:
                new_entries, crawl_warnings = crawl_and_extract(
                    urls,
                    topics=topics,
                    max_terms_per_source=max_terms,
                    proficiency=proficiency,
                )
                results = merge_vocab(results, new_entries)
                warnings.extend(crawl_warnings)

            if manual_text.strip():
                try:
                    payload = generate_vocab_from_context(
                        manual_text,
                        topics=topics,
                        max_terms=max_terms,
                        proficiency=proficiency,
                        source="Manual input",
                    )
                    results = merge_vocab(results, payload.get("entries", []))
                    if payload.get("notes"):
                        warnings.append(payload["notes"])
                except AIClientError as exc:
                    warnings.append(f"Manual text extraction failed: {exc}")

        st.session_state.builder_results = results
        st.session_state.builder_warnings = warnings
        if not results:
            st.warning("No vocabulary extracted. Double-check network access or refine your inputs.")

if st.session_state.builder_results:
    st.success(f"âœ… {len(st.session_state.builder_results)}ê°œ ë‹¨ì–´ ì¶”ì¶œ ì™„ë£Œ!")
    st.dataframe(st.session_state.builder_results, use_container_width=True)

    yaml_blob = export_to_yaml(st.session_state.builder_results)
    st.download_button(
        "â¬‡ï¸ YAML íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        data=yaml_blob,
        file_name="slavatalk_deck.yaml",
        mime="application/x-yaml",
    )

    if st.button("ğŸ’¾ ë©”ì¸ ë‹¨ì–´ì¥ì— ë³‘í•©í•˜ê¸°"):
        current = load_vocab()
        merged = merge_vocab(current, st.session_state.builder_results)
        save_vocab(merged)
        st.success(f"âœ… data/vocabulary.json ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ {len(merged)}ê°œ ë‹¨ì–´")

if st.session_state.builder_warnings:
    st.warning("Warnings:\n- " + "\n- ".join(st.session_state.builder_warnings))

st.markdown("---")
st.subheader("ğŸ“¤ Step 2. YAML/JSON íŒŒì¼ ì—…ë¡œë“œ")

uploaded = st.file_uploader("ğŸ’¾ YAML ë˜ëŠ” JSON ë‹¨ì–´ì¥ íŒŒì¼ ì—…ë¡œë“œ", type=["yaml", "yml", "json"])
if uploaded:
    try:
        content = uploaded.getvalue().decode("utf-8")
        imported_entries = parse_yaml(content)
        st.write(f"âœ… {len(imported_entries)}ê°œ ë‹¨ì–´ ë¡œë“œ ì™„ë£Œ")
        st.dataframe(imported_entries, use_container_width=True)
    except Exception as exc:
        st.error(f"âŒ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {exc}")
        imported_entries = []

    if imported_entries and st.button("ğŸ’¾ ì—…ë¡œë“œí•œ ë‹¨ì–´ ë³‘í•©í•˜ê¸°"):
        current = load_vocab()
        merged = merge_vocab(current, imported_entries)
        save_vocab(merged)
        st.success(f"âœ… ë³‘í•© ì™„ë£Œ! í˜„ì¬ ì´ {len(merged)}ê°œ ë‹¨ì–´")

st.markdown("---")
st.caption("ğŸ’¡ íŒ: YAML íŒŒì¼ì„ Gitìœ¼ë¡œ ê´€ë¦¬í•˜ê³  íŒ€ì›ë“¤ê³¼ ê³µìœ í•˜ì„¸ìš”!")
