#!/usr/bin/env python3
"""
226Í∞ú Í∏∞Ï¥àÏßÄÏûêÏ≤¥ Ï†ÑÏàòÏ°∞ÏÇ¨ ÌÅ¨Î°§ÎßÅ Ïä§ÌÅ¨Î¶ΩÌä∏ (Î≥ëÎ†¨ Ï≤òÎ¶¨)
"""

import sys
import os
import json
import time
import traceback
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from council_crawler import load_basic_councils_from_yaml, get_crawler, ResultSaver

# Ïä§Î†àÎìú ÏïàÏ†ÑÌïú Ï∂úÎ†•
print_lock = threading.Lock()

def safe_print(*args, **kwargs):
    with print_lock:
        print(*args, **kwargs, flush=True)

def crawl_single_council(code, config, max_pages, output_dir):
    """Îã®Ïùº ÏùòÌöå ÌÅ¨Î°§ÎßÅ"""
    name = config.get('name', code)
    crawler_type = config.get('crawler_type', 'default')
    note = config.get('note', '')

    result = {
        'code': code,
        'name': name,
        'crawler_type': crawler_type,
        'status': 'unknown',
        'reason': '',
        'meetings': 0,
        'size_bytes': 0,
        'avg_content_len': 0,
        'min_content_len': 0,
        'truncation_count': 0
    }

    # SSL Î¨∏Ï†ú Îì± ÏïåÎ†§ÏßÑ Ïù¥Ïäà
    if 'SSL' in note or 'Ï†ëÍ∑º Î∂àÍ∞Ä' in note:
        result['status'] = 'skip'
        result['reason'] = note
        return result

    try:
        crawler = get_crawler(code)
        if not crawler:
            result['status'] = 'fail'
            result['reason'] = 'ÌÅ¨Î°§Îü¨ ÏÉùÏÑ± Ïã§Ìå®'
            return result

        # ÌÅ¨Î°§ÎßÅ Ïã§Ìñâ
        meetings = []
        content_lengths = []
        truncation_count = 0

        for meeting in crawler.crawl(max_pages=max_pages):
            meetings.append(meeting)
            fc_len = len(meeting.full_content) if meeting.full_content else 0
            content_lengths.append(fc_len)

            if fc_len > 0 and fc_len < 500:
                truncation_count += 1

        if meetings:
            saver = ResultSaver(output_dir)
            md_file = saver.save_markdown(code, meetings)
            saver.save_jsonl(code, meetings)

            file_size = md_file.stat().st_size if md_file.exists() else 0
            avg_len = sum(content_lengths) / len(content_lengths) if content_lengths else 0
            min_len = min(content_lengths) if content_lengths else 0

            result['status'] = 'success'
            result['meetings'] = len(meetings)
            result['size_bytes'] = file_size
            result['avg_content_len'] = avg_len
            result['min_content_len'] = min_len
            result['truncation_count'] = truncation_count
        else:
            result['status'] = 'empty'
            result['reason'] = 'ÌöåÏùòÎ°ù ÏóÜÏùå'

    except Exception as e:
        result['status'] = 'error'
        result['reason'] = str(e)[:200]

    return result


def crawl_all_parallel(max_pages=5, output_dir="output/basic_minutes", workers=10):
    """Î≥ëÎ†¨ ÌÅ¨Î°§ÎßÅ"""
    basic_councils = load_basic_councils_from_yaml()

    print(f"=" * 80)
    print(f"üìä 226Í∞ú Í∏∞Ï¥àÏßÄÏûêÏ≤¥ Ï†ÑÏàòÏ°∞ÏÇ¨ (Î≥ëÎ†¨ {workers} workers)")
    print(f"=" * 80)
    print(f"ÎåÄÏÉÅ: {len(basic_councils)}Í∞ú")
    print(f"ÏãúÏûë: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"=" * 80)

    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # ÏßÑÌñâ ÏÉÅÌÉú
    progress_file = Path(output_dir) / "_progress.json"
    completed_codes = set()
    if progress_file.exists():
        with open(progress_file, 'r') as f:
            completed_codes = set(json.load(f).get('completed', []))
        print(f"‚è© Ïù¥Ï†Ñ ÏßÑÌñâ: {len(completed_codes)}Í∞ú ÏôÑÎ£åÎê®")

    # ÎØ∏ÏôÑÎ£å ÏùòÌöåÎßå ÌïÑÌÑ∞ÎßÅ
    pending = [(code, cfg) for code, cfg in basic_councils.items() if code not in completed_codes]
    print(f"ÎåÄÍ∏∞: {len(pending)}Í∞ú")

    results = []
    success = 0
    fail = 0
    total_meetings = 0
    total_size = 0
    truncation_issues = []

    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {
            executor.submit(crawl_single_council, code, cfg, max_pages, output_dir): (code, cfg)
            for code, cfg in pending
        }

        for i, future in enumerate(as_completed(futures), 1):
            code, cfg = futures[future]
            try:
                result = future.result(timeout=300)
                results.append(result)

                status_icon = {
                    'success': '‚úÖ',
                    'fail': '‚ùå',
                    'error': '‚ùå',
                    'skip': '‚è≠Ô∏è',
                    'empty': '‚ö†Ô∏è'
                }.get(result['status'], '?')

                if result['status'] == 'success':
                    success += 1
                    total_meetings += result['meetings']
                    total_size += result['size_bytes']

                    trunc_warn = ""
                    if result['truncation_count'] > 0:
                        trunc_warn = f" ‚ö†Ô∏è{result['truncation_count']}<500"
                        truncation_issues.append(result)

                    safe_print(f"[{i:3d}/{len(pending)}] {result['name']:<16} {status_icon} {result['meetings']:3d}Í∞ú {result['size_bytes']/1024:6.1f}KB{trunc_warn}")

                    # ÏßÑÌñâ Ï†ÄÏû•
                    completed_codes.add(code)
                    with open(progress_file, 'w') as f:
                        json.dump({'completed': list(completed_codes), 'ts': datetime.now().isoformat()}, f)
                else:
                    fail += 1
                    safe_print(f"[{i:3d}/{len(pending)}] {result['name']:<16} {status_icon} {result['reason'][:30]}")

            except Exception as e:
                fail += 1
                safe_print(f"[{i:3d}/{len(pending)}] {cfg.get('name', code):<16} ‚ùå timeout/error")

    # Ïù¥Ï†Ñ ÏôÑÎ£åÎêú Í≤ÉÎèÑ Ìè¨Ìï®
    for code in completed_codes:
        if code in basic_councils and not any(r['code'] == code for r in results):
            # ÌååÏùºÏóêÏÑú Ï†ïÎ≥¥ ÏùΩÍ∏∞
            md_file = Path(output_dir) / f"{code}.md"
            if md_file.exists():
                success += 1
                total_size += md_file.stat().st_size

    # ÏµúÏ¢Ö Ï†ÄÏû•
    summary = {
        'timestamp': datetime.now().isoformat(),
        'total': len(basic_councils),
        'success': success,
        'fail': fail,
        'total_meetings': total_meetings,
        'total_size_mb': total_size / 1024 / 1024,
        'truncation_issues': truncation_issues,
        'results': results
    }

    with open(Path(output_dir) / "_summary.json", 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print(f"\n{'=' * 80}")
    print(f"üìä ÏôÑÎ£å: ÏÑ±Í≥µ {success} / Ïã§Ìå® {fail}")
    print(f"Ï¥ù ÌöåÏùòÎ°ù: {total_meetings:,}Í∞ú")
    print(f"Ï¥ù Ïö©Îüâ: {total_size/1024/1024:.1f}MB")
    if truncation_issues:
        print(f"‚ö†Ô∏è 500Ïûê ÎØ∏Îßå ÏùòÏã¨: {len(truncation_issues)}Í∞ú")
    print(f"{'=' * 80}")

    return summary


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--max-pages', type=int, default=5)
    parser.add_argument('--output', default='output/basic_minutes')
    parser.add_argument('--workers', type=int, default=10)
    args = parser.parse_args()

    crawl_all_parallel(args.max_pages, args.output, args.workers)
