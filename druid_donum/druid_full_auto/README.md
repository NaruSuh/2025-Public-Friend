# 🌲 산림청 입찰정보 크롤러

산림청 웹사이트의 입찰공고 정보를 자동으로 수집하여 엑셀/CSV 파일로 저장하는 프로그램입니다.

## ✨ 주요 기능

- 🔍 **연도별 수집 기간 설정** - 1년부터 10년까지 선택 가능
- 📥 **다중 파일 포맷** - Excel (.xlsx), CSV (.csv) 지원
- 📋 **실시간 로그 추적** - 크롤링 과정 상세 로그 제공
- 💾 **로그 다운로드** - 마크다운(.md) 형식으로 저장 가능
- ⚡ **원터치 자동화** - 크롤링부터 파일 생성까지 한 번에
- 🎨 **웹 기반 UI** - 직관적인 Streamlit 인터페이스

## 🎯 사용 방법

### 🖥️ Streamlit 웹 앱 (권장)

```bash
streamlit run app.py
```

브라우저에서 `http://localhost:8501` 접속

#### 웹 앱 사용법

1. **사이드바에서 설정 조정**
   - 수집 기간: 1~10년 선택
   - 요청 간 딜레이: 0.5~3.0초
   - 페이지 간 딜레이: 0.5~5.0초

2. **크롤링 모드 선택**
   - **🚀 크롤링 시작**: 기본 크롤링 모드
   - **📥 크롤링 및 완료시 엑셀파일 작성**: 원터치 자동화 모드

3. **결과 확인 및 다운로드**
   - 실시간 진행 상황 확인
   - 통계 정보 및 데이터 미리보기
   - Excel/CSV 파일 다운로드
   - 로그 보기 및 다운로드

### 💻 CLI 버전

```bash
python3 main.py
```

## 프로젝트 구조 (3-Files System)

```
2025 Druid Full-auto Firing/
├── prompt.md          # 프로젝트 명세 및 요구사항
├── plan.md           # 구현 계획 및 아키텍처
├── main.py           # 크롤러 엔진
├── app.py            # Streamlit 웹 앱
├── requirements.txt  # 의존성 라이브러리
├── DEPLOY.md         # 배포 가이드
└── README.md         # 사용 설명서 (본 문서)
```

## 설치 방법

### 1. Python 환경 확인
Python 3.8 이상이 필요합니다.

```bash
python --version
```

### 2. 의존성 설치

```bash
pip install -r requirements.txt
```

또는 개별 설치:

```bash
pip install requests beautifulsoup4 pandas openpyxl lxml streamlit
```

## CLI 사용 방법

### 기본 실행

```bash
cd "/home/naru/work/2025_Vibe/2025 Druid Donum/2025 Druid Full-auto Firing"
python3 main.py
```

### 실행 결과

프로그램 실행 시:

1. 산림청 입찰공고 게시판에서 최근 1년치 데이터를 수집합니다
2. 각 페이지를 순회하며 게시글 상세 정보를 추출합니다
3. 진행 상황이 콘솔에 표시됩니다
4. 완료 후 엑셀 파일이 생성됩니다

**출력 예시:**
```
============================================================
  산림청 입찰정보 크롤러
============================================================
[*] 산림청 입찰정보 크롤링 시작...
[*] 수집 기간: 최근 365일 (기준일: 2024-10-04)

[*] 페이지 1 처리 중...
  [1/10] 2024년 ○○ 산림사업 입찰공고...
  [2/10] ○○지방산림청 △△ 조달 입찰...
  ...

[✓] 크롤링 완료: 총 1,234개 항목 수집
[✓] 엑셀 파일 저장: 산림청_입찰정보_20241004_153022.xlsx
```

### 중단 및 재개

- **Ctrl+C**로 중단 가능
- 중단 시 수집된 데이터는 자동으로 저장됩니다
- 매 10페이지마다 중간 저장 파일이 생성됩니다

## 📊 출력 파일 형식

Excel (.xlsx) 또는 CSV (.csv) 형식으로 다음 정보를 포함합니다:

| 컬럼명 | 설명 |
|--------|------|
| 번호 | 게시글 번호 |
| 제목 | 입찰공고 제목 |
| 분류 | 공고 분류/유형 |
| 담당산림청 | 관할 지방산림청 |
| 담당부서 | 세부 담당 부서명 |
| 담당자 | 담당자 이름 |
| 연락처 | 전화번호/이메일 |
| 공고일자 | 게시 날짜 |
| 조회수 | 게시글 조회 수 |
| 첨부파일 | 첨부파일 유무 (O/공백) |
| 첨부파일링크 | 첨부파일 다운로드 링크 |
| URL | 상세 페이지 URL |

## ⚙️ 설정 변경

### 웹 앱 (app.py)
사이드바에서 실시간으로 조정 가능:
- **수집 기간**: 1~10년 (슬라이더)
- **요청 간 딜레이**: 0.5~3.0초
- **페이지 간 딜레이**: 0.5~5.0초

### CLI 버전 (main.py)
`main()` 함수에서 파라미터 조정:

```python
crawler = ForestBidCrawler(
    days=365,      # 수집 기간 (일 단위) - 웹앱에서는 years * 365
    delay=1.0,     # 요청 간 대기 시간 (초)
    page_delay=2.0 # 페이지 간 대기 시간 (초)
)
```

## ⚠️ 주의사항

1. **서버 부하 최소화**: 기본 딜레이 설정(요청 1초, 페이지 2초) 유지 권장
2. **네트워크 안정성**: 안정적인 인터넷 연결 필수
3. **장시간 실행**: 수집 기간에 따라 수 분~수십 분 소요
   - 1년: 약 5~10분
   - 5년: 약 30~60분
   - 10년: 약 1~2시간
4. **법적 준수**: 공개된 정보만 수집, 연구 목적으로만 사용
5. **파일 다운로드**: 브라우저 기본 다운로드 폴더에 저장됨 (~/Downloads)

## 🚀 배포 방법

자세한 배포 가이드는 [DEPLOY.md](DEPLOY.md)를 참고하세요.

### 빠른 배포 (Streamlit Cloud)

1. GitHub에 코드 업로드
2. https://streamlit.io/cloud 에서 배포
3. 클릭 몇 번으로 완료!

### 지원 플랫폼

- ✅ Streamlit Cloud (무료, 권장)
- ✅ Hugging Face Spaces
- ✅ Heroku
- ✅ Docker
- ✅ AWS/GCP

## 문제 해결

### requests 오류
```bash
pip install --upgrade requests
```

### 엑셀 파일 열리지 않음
```bash
pip install --upgrade openpyxl
```

### Streamlit 포트 변경
```bash
streamlit run app.py --server.port 8080
```

### 파싱 오류
- 산림청 웹사이트 구조가 변경되었을 수 있습니다
- `plan.md`를 참고하여 셀렉터를 수정하세요

## 라이센스

개인 연구용

## 작성자

산림공학 전문가 / 산림학 연구자
